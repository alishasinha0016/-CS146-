For each of the following recurrences, verify the answer you get by applying the master method, 
by solving the recurrence algebraically OR applying the recursion tree method. 

1.    T(N) = 2T(N-1) + 1
2.    T(N) = 3T(N-1) + n
3.    T(N) = 9T(N/2) + n^2
4.    T(N) = 100T(N/2) + n^logcn + 1  (c is a constant)
5.    T(N) = 4T(N/2) + n^2logn
6.    T(N) = 5T(N/2) + n^2/logn

Answers: 
First, applying Master Theorem:
It is a decreasing function.
Therefore, 
a = 2, b =1
f(N) = 1
O(f(N)*a^(N/b)) = O(1*2^N) = O(2^N)

Now, solving the equation algebriacally, we get:
1.  T(N) = 2T(N-1) + 1         eq. 1

T(N-1) = 2T(N-2) + 1           eq. 2  
T(N-2) = 2T(N-3) + 1           eq. 3
Now, stustituting eq. 3 in eq. 2, we get,

T(N-1) = 2(2T(N-3)+1) + 1
T(N-1) = 4T(N-3)+ 3             eq. 4
Now, stustituting eq. 4 in eq. 1, we get,
T(N) = 2(4T(N-3)+3)+1
T(N) = 8T(N-3)+7
Hence, we can say that,
T(N) = 2^k(N-k) + 2^k -1

When k = N, N-k = 0, so we get:
T(N) = 2^NT(0) + 2^0 + 2^1 + ... + 2^(N-1)
= 2^N + (2^N - 1)
= 2^(N+1) - 1
= O(2^N)

Hence, the time complexity for T(N) is = O(2^N).

2. T(N) = 3T(N-1) + n

First, applying Master Theorem:
It is a decreasing function.
Therefore, 
a = 3, b =1
f(N) = n
O(f(N)*a^(N/b)) = O(n*3^N) = O(n*3^N)

T(N) = 3T(N-1) + n  eq. 1
T(N-1) = 3T(N-2) + n   eq. 2
T(N-2) = 3T(N-3) + n   eq. 3

Now, substituting eq. 3 in eq. 2, we get,
T(N-1) = 3(3T(N-3)+n) +n
T(N-1) = 9T(N-3) + 4n  eq. 4

Now, substituting eq. 4 in eq. 1, we get,
T(N) = 3(9T(N-3) + 4n) + n
T(N) = 27T(N-3) + 13n
we can write it as,
T(N) = 3^kT(N-1-k) + 3^&k(k−1)+3^k−1(k−2)+...+3⋅2+ n
Therefore, the complexity is O(n*3^N)

3. T(N) = 9T(N/2) + n^2
This falls into case 1 of the Master Theorem with a = 9, b = 2, k = 2, p = 0, and f(N) = N^2. 
Because N^log⁡b(a) = N^log⁡2(9) = 2.19 > k = 2  

Therefore, the time complexity is O(N^log⁡b(a)) = O(N^log2(9)) = O(N^ln(9)) = O(N^2.19).

Solving it using tree method, we get:
                T(N)
                / |       \          ... 9 branches  ------> n^2
          T(N/2) T(N/2) T(N/2) ... T(N/2)
           /|\        /|\       /|\       /|\
     T(N/4) ... T(N/4) ... T(N/4) ... T(N/4) ... T(N/4)  ------> n^2
       /|\               /|\               /|\               /|\   .... Continues till we reach T(1) or the termination point


At each level, we have n^2 work to do (from the n^2 term in the recurrence relation). Since there are log⁡N levels 
(as the problem size decreases by half at each level), the total work done at each level is n^2. 
Therefore, the total work done is the sum of the work done at each level, which is O(n^2⋅log⁡N).

Note: In the master theorem, we had logb(a) = 2.19 which is approximately equal to k which is 2.
In that case, it would fall under case 2 and then the time complexity would be O(N^2*logN)

4. T(N) = 100T(N/2) + n^(logcn + 1 ) (c is a constant)
Master Theorem with a=100, b=2, k = logcn + 1, p = 0, and f(N)=n^logcn + 1. 
Here we can see that,
log⁡b(a) = log⁡2(100) = 4.6 < k (as c is a consant and can take any number)
Therefore, it it fals under case 3:
Since, p = 0
Therefore, the time complexity is O(N^k*(log⁡N)) = O(N^(logcn + 1 )*(log⁡N))

Now, solving it using tree method, we get:
                T(N)
                / | |   ... 100 branches ------>  n^(logcn + 1 )
          T(N/2) T(N/2) T(N/2) ... T(N/2)
           /|\        /|\       /|\       /|\
     T(N/4) ... T(N/4) ... T(N/4) ... T(N/4) ... T(N/4) ------>  n^(logcn + 1 )
       /|\               /|\               /|\               /|\ ..... Till we reach T(1) or the termination point

Here we can see that, at each level, we have n^(logcn + 1 ) work to do (from the n^(logcn + 1 ) term in the recurrence relation). 
As we know that, there are log⁡N levels (as the problem size decreases by half at each level), 
the total work done at each level is n^(logcn + 1 ). 
Therefore, the total work done is the sum of the work done at each level, which is O(n^(log⁡(cn)+1)⋅log⁡(n))


5. T(N) = 4T(N/2) + n^2logn
This falls into case 3 of the Master Theorem with a=4, b=2, k = 2, p = 1, and f(N)=n^2logn.
Now, we can see that,
log⁡b(a) = log⁡2(4) = 2 = k
Therefore, it falls under case 2:
Since, p > -1
Time complexity = O(n^2 * (log n)^2)

Now, solving it using substitution method, we get;

                     T(N)
            /     |       \        \
          T(N/2) T(N/2) T(N/2) T(N/2)     -----> n^2logn time
           /|\        /|\       /|\       /|\
     T(N/4) ... T(N/4) ... T(N/4) ... T(N/4)   ------> n^2logn/2
       /|\               /|\               /|\ ..... till we reach T(1)

At each level, we have a total of n^2 log n work to do (from the n^2 log n term in the recurrence relation). 
Since there are log N levels (as the problem size decreases by half at each level), the total work done at each 
level is n^2 log n. Therefore, the total work done is the sum of the work done would be n^2 (log n)*(log n)
Hence, the time complexity = O(n^2 (log n)^2).



6. T(N) = 5T(N/2) + n^2/logn
Applying the Master Theorem with a=5, b=2, k = 2, p  -1, and f(N)=n^2/logn
Now, we can see that,
logb(​a) = log2(​5) = 2.32 > k
Therefore, it falls under case 1. Hence, the time complexity is O(n^log2(​5)) = O(n^2.32) .

Now, using tree method to solve this problem, we get:


                       T(N)
             /      /    |      \      \
          T(N/2) T(N/2) T(N/2) T(N/2) T(N/2)    ------> n^2/logn
           /|\        /|\       /|\       /|\
     T(N/4) ... T(N/4) ... T(N/4) ... T(N/4) ... T(N/4)   ------> n^2/log(n/2)
       /|\               /|\               /|\               /|\ ..... till we reach T(1) or the termination point


Here we can see that, at each level, we have n^2/log⁡n work to do (from the n^2/log⁡n term in the recurrence relation). 
Since there are log⁡N levels (as the problem size decreases by half at each level), the total work done 
at each level is (n^2/log⁡n) and total would be (n^2/log⁡n)*logn = n^2.  
Therefore, the total work done is the sum of the work done at each level, which is O(n^2).





